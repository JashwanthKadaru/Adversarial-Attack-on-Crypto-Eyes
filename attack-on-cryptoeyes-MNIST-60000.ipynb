{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a535fdce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:35:06.679355Z",
     "iopub.status.busy": "2025-02-23T04:35:06.679072Z",
     "iopub.status.idle": "2025-02-23T04:35:15.685603Z",
     "shell.execute_reply": "2025-02-23T04:35:15.684899Z"
    },
    "papermill": {
     "duration": 9.01137,
     "end_time": "2025-02-23T04:35:15.687300",
     "exception": false,
     "start_time": "2025-02-23T04:35:06.675930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from Crypto.Cipher import AES\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Load MNIST without scaling\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape(-1, 28, 28).astype(np.uint8)\n",
    "test_images = test_images.reshape(-1, 28, 28).astype(np.uint8)\n",
    "\n",
    "block_size = 4\n",
    "num_blocks = (28 // block_size) ** 2\n",
    "permutation_sequence = np.random.permutation(num_blocks)\n",
    "key_pool = [AES.new(bytes([random.randint(0, 255) for _ in range(16)]), AES.MODE_ECB) for _ in range(1000)]\n",
    "\n",
    "# Helper function to encrypt and permute images\n",
    "def encrypt_permute_image(image, aes_key, permutation_sequence):\n",
    "    encrypted_blocks = []\n",
    "    for i in range(0, 28, block_size):\n",
    "        for j in range(0, 28, block_size):\n",
    "            block = image[i:i+block_size, j:j+block_size].flatten()\n",
    "            encrypted_block = aes_key.encrypt(block.tobytes())\n",
    "            encrypted_blocks.append(np.frombuffer(encrypted_block, dtype=np.uint8).reshape(block_size, block_size))\n",
    "    # Apply permutation\n",
    "    permuted_blocks = [encrypted_blocks[idx] for idx in permutation_sequence]\n",
    "    # Reconstruct image\n",
    "    permuted_image = np.zeros_like(image, dtype=np.uint8)\n",
    "    idx = 0\n",
    "    for i in range(0, 28, block_size):\n",
    "        for j in range(0, 28, block_size):\n",
    "            permuted_image[i:i+block_size, j:j+block_size] = permuted_blocks[idx]\n",
    "            idx += 1\n",
    "    return permuted_image\n",
    "\n",
    "# Encrypt and permute test images as usual\n",
    "def prepare_test_dataset(images, labels, key_pool, permutation_sequence, ratio=0.2):\n",
    "    num_samples = int(len(images) * ratio)\n",
    "    selected_indices = np.random.choice(len(images), num_samples, replace=False)\n",
    "    selected_images = images[selected_indices]\n",
    "    selected_labels = labels[selected_indices][:num_samples]  # Fixed to match number of samples\n",
    "    \n",
    "    encrypted_test_images = []\n",
    "    for image in tqdm(selected_images):\n",
    "        key = random.choice(key_pool)\n",
    "        encrypted_image = encrypt_permute_image(image, key, permutation_sequence)\n",
    "        encrypted_test_images.append(encrypted_image)\n",
    "    return np.array(encrypted_test_images, dtype=np.uint8), selected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f4d6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:35:15.692664Z",
     "iopub.status.busy": "2025-02-23T04:35:15.692198Z",
     "iopub.status.idle": "2025-02-23T04:35:15.697130Z",
     "shell.execute_reply": "2025-02-23T04:35:15.696415Z"
    },
    "papermill": {
     "duration": 0.008755,
     "end_time": "2025-02-23T04:35:15.698446",
     "exception": false,
     "start_time": "2025-02-23T04:35:15.689691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_train_test_sets(train_images, train_labels, test_images, test_labels, key_pool, permutation_sequence):\n",
    "    # Encryption & Permutation\n",
    "    encrypted_train_images = [encrypt_permute_image(img, random.choice(key_pool[:100]), permutation_sequence) for img in tqdm(train_images)]\n",
    "    \n",
    "    # train dataset ready.... (encrypted_train_images, train_labels)\n",
    "    train_images_final = np.concatenate([encrypted_train_images])\n",
    "    train_labels_final = np.concatenate([train_labels])\n",
    "    \n",
    "    print('done')\n",
    "\n",
    "    # test dataset ready\n",
    "    test_images_encrypted, test_labels_encrypted = prepare_test_dataset(test_images, test_labels, key_pool[100:1000], permutation_sequence, 1.0)\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "    train_images_final=train_images_final.reshape(-1, 28, 28, 1)/255.0\n",
    "    test_images_encrypted=test_images_encrypted.reshape(-1, 28, 28, 1)/255.0\n",
    "    \n",
    "    return train_images_final, train_labels_final, test_images_encrypted, test_labels_encrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98075c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:35:15.702967Z",
     "iopub.status.busy": "2025-02-23T04:35:15.702711Z",
     "iopub.status.idle": "2025-02-23T04:35:15.714291Z",
     "shell.execute_reply": "2025-02-23T04:35:15.713662Z"
    },
    "papermill": {
     "duration": 0.015175,
     "end_time": "2025-02-23T04:35:15.715516",
     "exception": false,
     "start_time": "2025-02-23T04:35:15.700341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Define gradient map computation for contour extraction with 4x4 kernel\n",
    "def compute_gradient_map(images):\n",
    "    gx_filter = tf.constant([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=tf.float32, shape=[3, 3, 1, 1])\n",
    "    gy_filter = tf.constant([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=tf.float32, shape=[3, 3, 1, 1])\n",
    "    gx = tf.nn.conv2d(images, gx_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    gy = tf.nn.conv2d(images, gy_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    gradient_map = tf.sqrt(tf.add(tf.square(gx), tf.square(gy)))\n",
    "    return gradient_map\n",
    "\n",
    "# Define the classification model with an LSTM head\n",
    "def create_cryptoeyes_model(input_shape=(28, 28, 1)):\n",
    "    # First input: encrypted images\n",
    "    input_images = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Second input: pre-computed gradient maps\n",
    "    input_gradient_maps = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Stream for encrypted images\n",
    "    conv1_enc = layers.Conv2D(32, (1, 16), padding='same')(input_images)\n",
    "    conv1_enc = layers.LeakyReLU(alpha=0.01)(conv1_enc)\n",
    "    gate1_enc = layers.Conv2D(32, (1, 16), activation='sigmoid', padding='same')(input_images)\n",
    "    gated1_enc = layers.Multiply()([conv1_enc, gate1_enc])\n",
    "    avg1_enc = layers.Average()([gated1_enc, conv1_enc])\n",
    "    pool1_enc = layers.MaxPooling2D((2, 2))(avg1_enc)\n",
    "    \n",
    "    conv2_enc = layers.Conv2D(64, (1, 16), padding='same')(pool1_enc)\n",
    "    conv2_enc = layers.LeakyReLU(alpha=0.01)(conv2_enc)\n",
    "    gate2_enc = layers.Conv2D(64, (1, 16), activation='sigmoid', padding='same')(pool1_enc)\n",
    "    gated2_enc = layers.Multiply()([conv2_enc, gate2_enc])\n",
    "    avg2_enc = layers.Average()([gated2_enc, conv2_enc])\n",
    "    pool2_enc = layers.MaxPooling2D((2, 2))(avg2_enc)\n",
    "    \n",
    "    flat_enc = layers.Flatten()(pool2_enc)\n",
    "    \n",
    "    # Stream for gradient maps\n",
    "    conv1_grad = layers.Conv2D(32, (1, 16), padding='same')(input_gradient_maps)\n",
    "    conv1_grad = layers.LeakyReLU(alpha=0.01)(conv1_grad)\n",
    "    gate1_grad = layers.Conv2D(32, (1, 16), activation='sigmoid', padding='same')(input_gradient_maps)\n",
    "    gated1_grad = layers.Multiply()([conv1_grad, gate1_grad])\n",
    "    avg1_grad = layers.Average()([gated1_grad, conv1_grad])\n",
    "    pool1_grad = layers.MaxPooling2D((2, 2))(avg1_grad)\n",
    "    \n",
    "    conv2_grad = layers.Conv2D(64, (1, 16), padding='same')(pool1_grad)\n",
    "    conv2_grad = layers.LeakyReLU(alpha=0.01)(conv2_grad)\n",
    "    gate2_grad = layers.Conv2D(64, (1, 16), activation='sigmoid', padding='same')(pool1_grad)\n",
    "    gated2_grad = layers.Multiply()([conv2_grad, gate2_grad])\n",
    "    avg2_grad = layers.Average()([gated2_grad, conv2_grad])\n",
    "    pool2_grad = layers.MaxPooling2D((2, 2))(avg2_grad)\n",
    "    \n",
    "    flat_grad = layers.Flatten()(pool2_grad)\n",
    "    \n",
    "    # Combine streams\n",
    "    combined = layers.Concatenate()([flat_enc, flat_grad])\n",
    "    reshaped = layers.Reshape((1, -1))(combined)  # Reshape to make it compatible with LSTM\n",
    "\n",
    "    # Optimized LSTM activation function\n",
    "    lstm_layer = layers.LSTM(128, return_sequences=False)(reshaped)\n",
    "    \n",
    "    output = layers.Dense(10, activation='softmax')(lstm_layer)  # Adjust the number of output classes as needed\n",
    "    \n",
    "    model = models.Model(inputs=[input_images, input_gradient_maps], outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.00005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997e79a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:35:15.720100Z",
     "iopub.status.busy": "2025-02-23T04:35:15.719879Z",
     "iopub.status.idle": "2025-02-23T04:39:19.060899Z",
     "shell.execute_reply": "2025-02-23T04:39:19.059989Z"
    },
    "papermill": {
     "duration": 243.34482,
     "end_time": "2025-02-23T04:39:19.062321",
     "exception": false,
     "start_time": "2025-02-23T04:35:15.717501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:17<00:00, 3347.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3352.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.1988 - loss: 2.1745 - val_accuracy: 0.4900 - val_loss: 1.5318\n",
      "Epoch 2/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5176 - loss: 1.4350 - val_accuracy: 0.5750 - val_loss: 1.2652\n",
      "Epoch 3/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5846 - loss: 1.2333 - val_accuracy: 0.6083 - val_loss: 1.1484\n",
      "Epoch 4/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6237 - loss: 1.1198 - val_accuracy: 0.6243 - val_loss: 1.0756\n",
      "Epoch 5/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6424 - loss: 1.0504 - val_accuracy: 0.6483 - val_loss: 1.0232\n",
      "Epoch 6/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6677 - loss: 0.9827 - val_accuracy: 0.6680 - val_loss: 0.9780\n",
      "Epoch 7/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6814 - loss: 0.9419 - val_accuracy: 0.6797 - val_loss: 0.9396\n",
      "Epoch 8/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6933 - loss: 0.9077 - val_accuracy: 0.6767 - val_loss: 0.9268\n",
      "Epoch 9/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7018 - loss: 0.8750 - val_accuracy: 0.6883 - val_loss: 0.8932\n",
      "Epoch 10/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7130 - loss: 0.8455 - val_accuracy: 0.6953 - val_loss: 0.8697\n",
      "Epoch 11/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7229 - loss: 0.8195 - val_accuracy: 0.7003 - val_loss: 0.8540\n",
      "Epoch 12/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7317 - loss: 0.7960 - val_accuracy: 0.7057 - val_loss: 0.8398\n",
      "Epoch 13/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7417 - loss: 0.7632 - val_accuracy: 0.7193 - val_loss: 0.8153\n",
      "Epoch 14/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7492 - loss: 0.7397 - val_accuracy: 0.7230 - val_loss: 0.8036\n",
      "Epoch 15/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7558 - loss: 0.7169 - val_accuracy: 0.7260 - val_loss: 0.7832\n",
      "Epoch 16/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7636 - loss: 0.7063 - val_accuracy: 0.7323 - val_loss: 0.7828\n",
      "Epoch 17/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.7685 - loss: 0.6867 - val_accuracy: 0.7357 - val_loss: 0.7610\n",
      "Epoch 18/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7761 - loss: 0.6655 - val_accuracy: 0.7423 - val_loss: 0.7545\n",
      "Epoch 19/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7839 - loss: 0.6430 - val_accuracy: 0.7370 - val_loss: 0.7544\n",
      "Epoch 20/20\n",
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7874 - loss: 0.6338 - val_accuracy: 0.7453 - val_loss: 0.7419\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.7262\n",
      "Test Accuracy: 0.7461, Test Loss: 0.7358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images_final, train_labels_final, test_images_encrypted, test_labels_encrypted = generate_train_test_sets(train_images, train_labels, test_images, test_labels, key_pool, permutation_sequence)\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "model = create_cryptoeyes_model(input_shape)\n",
    "\n",
    "# Split 5% of train data for validation\n",
    "train_images_train, val_images, train_labels_train, val_labels = train_test_split(\n",
    "    train_images_final, train_labels_final, test_size=0.05, random_state=42\n",
    ")\n",
    "\n",
    "# Compute gradient maps for train and validation\n",
    "train_gradients = compute_gradient_map(train_images_train)\n",
    "val_gradients = compute_gradient_map(val_images)\n",
    "\n",
    "# Train with validation data\n",
    "model.fit(\n",
    "    [train_images_train, train_gradients], train_labels_train,\n",
    "    validation_data=([val_images, val_gradients], val_labels),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    [test_images_encrypted, compute_gradient_map(test_images_encrypted)], \n",
    "    test_labels_encrypted, verbose=1\n",
    ")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 256.672091,
   "end_time": "2025-02-23T04:39:21.065573",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-23T04:35:04.393482",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
